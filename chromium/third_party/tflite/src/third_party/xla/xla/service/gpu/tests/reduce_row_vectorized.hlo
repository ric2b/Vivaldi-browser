// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/%{GPU}.txtpb | FileCheck %s --check-prefixes=CHECK,CHECK-%{PTX}

HloModule RowReductionVectorized, is_scheduled=true

Sum {
    x.1 = f32[] parameter(0)
    y.1 = f32[] parameter(1)
    ROOT add.1 = f32[] add(x.1, y.1)
}

fusion_vectorized {
    a = f32[131072,1024] parameter(0)
    init = f32[] constant(0)
    ROOT reduce = f32[131072] reduce(a, init), dimensions={1}, to_apply=Sum
}

ENTRY reduce.1 {
    parameter0 = f32[131072,1024] parameter(0)
    ROOT fusion_row_reduction_vectorized = f32[131072] fusion(
        f32[131072,1024] parameter0
    ), kind=kLoop, calls=fusion_vectorized
}

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = alloca float, align 4
// CHECK:         %[[VAL_1:.*]] = alloca float, align 4
// CHECK:         %[[VAL_2:.*]] = alloca float, align 4
// CHECK:         %[[VAL_3:.*]] = alloca float, align 4
// CHECK:         %[[VAL_4:.*]] = alloca float, align 4
// CHECK:         %[[VAL_5:.*]] = alloca float, align 4
// CHECK:         %[[VAL_6:.*]] = alloca float, align 4
// CHECK:         %[[VAL_7:.*]] = alloca float, align 4
// CHECK:         %[[VAL_8:.*]] = alloca float, align 4
// CHECK:         %[[VAL_9:.*]] = alloca float, align 4
// CHECK:         %[[VAL_10:.*]] = alloca float, align 4
// CHECK:         %[[VAL_11:.*]] = alloca float, align 4
// CHECK:         %[[VAL_12:.*]] = alloca float, align 4
// CHECK:         %[[VAL_13:.*]] = alloca float, align 4
// CHECK:         %[[VAL_14:.*]] = alloca float, align 4
// CHECK:         %[[VAL_15:.*]] = alloca float, align 4
// CHECK:         %[[VAL_16:.*]] = alloca float, align 4
// CHECK:         %[[VAL_17:.*]] = alloca float, align 4
// CHECK:         %[[VAL_18:.*]] = alloca float, align 4
// CHECK:         %[[VAL_19:.*]] = alloca float, align 4
// CHECK:         %[[VAL_20:.*]] = alloca float, align 4
// CHECK:         %[[VAL_21:.*]] = alloca float, align 4
// CHECK-PTX:     %[[VAL_22:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_23:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_24:.*]] = alloca float, align 4
// CHECK-PTX:     %[[VAL_25:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_26:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_27:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_28:.*]] = alloca float, align 4
// CHECK:         %[[VAL_29:.*]] = alloca float, align 4
// CHECK-PTX:     %[[VAL_30:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !2
// CHECK-GCN:     %[[VAL_30:.*]] = call i32 @llvm.amdgcn.workgroup.id.y
// CHECK:         %[[VAL_31:.*]] = icmp eq i32 %[[VAL_30]], 0
// CHECK:         br i1 %[[VAL_31]], label %[[VAL_32:.*]], label %[[VAL_33:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %thread_in_bounds-after, %[[VAL_34:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_34]]
// CHECK:         %[[VAL_35:.*]] = load float, ptr @0, align 4
// CHECK:         store float %[[VAL_35]], ptr{{.*}} %[[VAL_28]], align 4
// CHECK-PTX:     %thread.id.x = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !3
// CHECK-GCN:     %thread.id.x = call i32 @llvm.amdgcn.workitem.id.x
// CHECK-PTX:     %block.id.x = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
// CHECK-GCN:     %block.id.x = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %[[VAL_36:.*]] = udiv i32 %thread.id.x, 64
// CHECK:         %thread.id.1 = urem i32 %[[VAL_36]], 4
// CHECK:         %thread.id.2 = urem i32 %thread.id.x, 64
// CHECK:         %lane_id = urem i32 %thread.id.x, 32
// CHECK:         %[[VAL_37:.*]] = udiv i32 %block.id.x, 1
// CHECK:         %[[VAL_38:.*]] = urem i32 %[[VAL_37]], 1
// CHECK-PTX:     %[[VAL_39:.*]] = udiv i32 %block.id.x, 1
// CHECK-PTX:     %[[VAL_40:.*]] = urem i32 %[[VAL_39]], 1
// CHECK:         %[[VAL_41:.*]] = udiv i32 %block.id.x, 1
// CHECK:         %[[VAL_42:.*]] = urem i32 %[[VAL_41]], 32768
// CHECK:         %[[VAL_43:.*]] = udiv i32 %block.id.x, 32768
// CHECK:         %tile_origin.0 = mul i32 %[[VAL_43]], 1
// CHECK:         %tile_origin.1 = mul i32 %[[VAL_42]], 4
// CHECK-PTX:     %tile_origin.2 = mul i32 %[[VAL_40]], 512
// CHECK-GCN:     %tile_origin.2 = mul i32 %[[VAL_38]], 1024
// CHECK-PTX:     %tile_origin.3 = mul i32 %[[VAL_38]], 2
// CHECK:         store i32 %thread.id.1, ptr{{.*}} %[[VAL_27]], align 4
// CHECK:         br label %[[VAL_44:.*]]

// CHECK:       loop1.loop_header:                                ; preds = %[[VAL_45:.*]], %[[VAL_32]]
// CHECK:         %[[VAL_46:.*]] = load i32, ptr{{.*}} %[[VAL_27]], align 4
// CHECK:         %[[VAL_47:.*]] = icmp uge i32 %[[VAL_46]], 4
// CHECK:         br i1 %[[VAL_47]], label %[[VAL_48:.*]], label %[[VAL_49:.*]]

// CHECK:       loop1.loop_body:                                  ; preds = %[[VAL_44]]
// CHECK:         %[[VAL_50:.*]] = add nuw nsw i32 %[[VAL_46]], 4
// CHECK:         store i32 %[[VAL_50]], ptr{{.*}} %[[VAL_27]], align 4
// CHECK:         br i1 true, label %[[VAL_52:.*]], label %[[VAL_53:.*]]

// CHECK:       is_full_tile-after:                               ; preds = %[[VAL_54:.*]], %[[VAL_55:.*]]
// CHECK:         br label %[[VAL_44]], !llvm.loop !{{(5|4)}}

// CHECK:       loop1.loop_exit:                                  ; preds = %[[VAL_44]]
// CHECK:         %[[VAL_56:.*]] = load float, ptr{{.*}} %[[VAL_28]], align 4
// CHECK-GCN:     %[[VAL_57_1:.*]] = bitcast float %[[VAL_56]] to i32
// CHECK-GCN:     %[[VAL_57_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_57_1]], i32 543)
// CHECK-GCN:     %[[VAL_57:.*]] = bitcast i32 %[[VAL_57_2]] to float
// CHECK-PTX:     %[[VAL_57:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_56]], i32 16, i32 31)
// CHECK:         store float %[[VAL_57]], ptr{{.*}} %[[VAL_20]], align 4
// CHECK-GCN:     %[[VAL_58_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_28]] to ptr
// CHECK-GCN:     %[[VAL_58_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_20]] to ptr
// CHECK-GCN:     %[[VAL_58_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_19]] to ptr
// CHECK-GCN:     call void @[[SUM:Sum.*]](ptr %[[VAL_58_1]], ptr %[[VAL_58_2]], ptr %[[VAL_58_3]])
// CHECK-PTX:     call void @[[SUM:Sum.*]](ptr %[[VAL_28]], ptr %[[VAL_20]], ptr %[[VAL_19]])
// CHECK:         %[[VAL_58:.*]] = load float, ptr{{.*}} %[[VAL_19]], align 4
// CHECK:         store float %[[VAL_58]], ptr{{.*}} %[[VAL_28]], align 4
// CHECK:         %[[VAL_59:.*]] = load float, ptr{{.*}} %[[VAL_28]], align 4
// CHECK-GCN:     %[[VAL_60_1:.*]] = bitcast float %[[VAL_59]] to i32
// CHECK-GCN:     %[[VAL_60_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_60_1]], i32 287)
// CHECK-GCN:     %[[VAL_60:.*]] = bitcast i32 %[[VAL_60_2]] to float
// CHECK-PTX:     %[[VAL_60:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_59]], i32 8, i32 31)
// CHECK:         store float %[[VAL_60]], ptr{{.*}} %[[VAL_18]], align 4
// CHECK-GCN:     %[[VAL_61_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_28]] to ptr
// CHECK-GCN:     %[[VAL_61_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_18]] to ptr
// CHECK-GCN:     %[[VAL_61_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_17]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_61_1]], ptr %[[VAL_61_2]], ptr %[[VAL_61_3]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_28]], ptr %[[VAL_18]], ptr %[[VAL_17]])
// CHECK:         %[[VAL_61:.*]] = load float, ptr{{.*}} %[[VAL_17]], align 4
// CHECK:         store float %[[VAL_61]], ptr{{.*}} %[[VAL_28]], align 4
// CHECK:         %[[VAL_62:.*]] = load float, ptr{{.*}} %[[VAL_28]], align 4
// CHECK-GCN:     %[[VAL_63_1:.*]] = bitcast float %[[VAL_62]] to i32
// CHECK-GCN:     %[[VAL_63_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_63_1]], i32 159)
// CHECK-GCN:     %[[VAL_63:.*]] = bitcast i32 %[[VAL_63_2]] to float
// CHECK-PTX:     %[[VAL_63:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_62]], i32 4, i32 31)
// CHECK:         store float %[[VAL_63]], ptr{{.*}} %[[VAL_16]], align 4
// CHECK-GCN:     %[[VAL_64_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_28]] to ptr
// CHECK-GCN:     %[[VAL_64_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_16]] to ptr
// CHECK-GCN:     %[[VAL_64_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_15]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_64_1]], ptr %[[VAL_64_2]], ptr %[[VAL_64_3]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_28]], ptr %[[VAL_16]], ptr %[[VAL_15]])
// CHECK:         %[[VAL_64:.*]] = load float, ptr{{.*}} %[[VAL_15]], align 4
// CHECK:         store float %[[VAL_64]], ptr{{.*}} %[[VAL_28]], align 4
// CHECK:         %[[VAL_65:.*]] = load float, ptr{{.*}} %[[VAL_28]], align 4
// CHECK-GCN:     %[[VAL_66_1:.*]] = bitcast float %[[VAL_65]] to i32
// CHECK-GCN:     %[[VAL_66_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_66_1]], i32 95)
// CHECK-GCN:     %[[VAL_66:.*]] = bitcast i32 %[[VAL_66_2]] to float
// CHECK-PTX:     %[[VAL_66:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_65]], i32 2, i32 31)
// CHECK:         store float %[[VAL_66]], ptr{{.*}} %[[VAL_14]], align 4
// CHECK-GCN:     %[[VAL_67_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_28]] to ptr
// CHECK-GCN:     %[[VAL_67_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_14]] to ptr
// CHECK-GCN:     %[[VAL_67_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_13]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_67_1]], ptr %[[VAL_67_2]], ptr %[[VAL_67_3]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_28]], ptr %[[VAL_14]], ptr %[[VAL_13]])
// CHECK:         %[[VAL_67:.*]] = load float, ptr{{.*}} %[[VAL_13]], align 4
// CHECK:         store float %[[VAL_67]], ptr{{.*}} %[[VAL_28]], align 4
// CHECK:         %[[VAL_68:.*]] = load float, ptr{{.*}} %[[VAL_28]], align 4
// CHECK-GCN:     %[[VAL_69_1:.*]] = bitcast float %[[VAL_68]] to i32
// CHECK-GCN:     %[[VAL_69_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_69_1]], i32 63)
// CHECK-GCN:     %[[VAL_69:.*]] = bitcast i32 %[[VAL_69_2]] to float
// CHECK-PTX:     %[[VAL_69:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_68]], i32 1, i32 31)
// CHECK:         store float %[[VAL_69]], ptr{{.*}} %[[VAL_12]], align 4
// CHECK-GCN:     %[[VAL_70_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_28]] to ptr
// CHECK-GCN:     %[[VAL_70_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_12]] to ptr
// CHECK-GCN:     %[[VAL_70_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_11]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_70_1]], ptr %[[VAL_70_2]], ptr %[[VAL_70_3]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_28]], ptr %[[VAL_12]], ptr %[[VAL_11]])
// CHECK:         %[[VAL_70:.*]] = load float, ptr{{.*}} %[[VAL_11]], align 4
// CHECK:         store float %[[VAL_70]], ptr{{.*}} %[[VAL_28]], align 4
// CHECK:         %[[VAL_71:.*]] = udiv i32 %thread.id.2, 32
// CHECK:         %[[VAL_72:.*]] = icmp ult i32 %thread.id.1, 4
// CHECK:         br i1 %[[VAL_72]], label %thread_in_bounds-true, label %thread_in_bounds-after

// CHECK:       thread_in_bounds-after:                           ; preds = %[[VAL_73:.*]], %[[VAL_48]]
// CHECK:         br label %[[VAL_33]]

// CHECK:       is_full_tile-true:                                ; preds = %[[VAL_49]]
// CHECK:         store i32 0, ptr{{.*}} %[[VAL_26]], align 4
// CHECK:         br label %[[VAL_74:.*]]

// CHECK:       loop2.loop_header:                                ; preds = %[[VAL_75:.*]], %[[VAL_52]]
// CHECK:         %[[VAL_76:.*]] = load i32, ptr{{.*}} %[[VAL_26]], align 4
// CHECK-PTX:     %[[VAL_77:.*]] = icmp uge i32 %[[VAL_76]], 512
// CHECK-GCN:     %[[VAL_77:.*]] = icmp uge i32 %[[VAL_76]], 1024
// CHECK:         br i1 %[[VAL_77]], label %[[VAL_55]], label %[[VAL_78:.*]]

// CHECK:       loop2.loop_body:                                  ; preds = %[[VAL_74]]
// CHECK:         %[[VAL_79:.*]] = add nuw nsw i32 %[[VAL_76]], 64
// CHECK:         store i32 %[[VAL_79]], ptr{{.*}} %[[VAL_26]], align 4
// CHECK:         %[[VAL_81:.*]] = add i32 %[[VAL_76]], %thread.id.2
// CHECK-GCN:     %[[VAL_88:.*]] = add i32 %tile_origin.0, 0
// CHECK-GCN:     %[[VAL_89:.*]] = add i32 %tile_origin.1, %[[VAL_46]]
// CHECK-GCN:     %[[VAL_90:.*]] = add i32 %tile_origin.2, %[[VAL_81]]
// CHECK-GCN:     %[[VAL_102:.*]] = getelementptr inbounds [131072 x [1024 x float]], ptr %[[VAL_103:.*]], i32 0, i32 %[[VAL_89]], i32 %[[VAL_90]]
// CHECK-GCN:     %[[VAL_104:.*]] = load float, ptr %[[VAL_102]], align 4, !invariant.load !6
// CHECK-GCN:     store float %[[VAL_104]], ptr{{.*}} %[[VAL_29]], align 4
// CHECK-GCN:     %[[VAL_105_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_28]] to ptr
// CHECK-GCN:     %[[VAL_105_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_29]] to ptr
// CHECK-GCN:     %[[VAL_105_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_24]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_105_1]], ptr %[[VAL_105_2]], ptr %[[VAL_105_3]])
// CHECK-GCN:     %[[VAL_105:.*]] = load float, ptr{{.*}} %[[VAL_24]], align 4
// CHECK-GCN:     store float %[[VAL_105]], ptr{{.*}} %[[VAL_28]], align 4
// CHECK-PTX:     store i32 0, ptr %[[VAL_25]], align 4
// CHECK:         br label %[[VAL_82:.*]]

// CHECK-PTX:   loop3.loop_header:                                ; preds = %[[VAL_83:.*]], %[[VAL_78]]
// CHECK-PTX:     %[[VAL_84:.*]] = load i32, ptr %[[VAL_25]], align 4
// CHECK-PTX:     %[[VAL_85:.*]] = icmp uge i32 %[[VAL_84]], 2
// CHECK-PTX:     br i1 %[[VAL_85]], label %[[VAL_75]], label %[[VAL_83]]

// CHECK-PTX:   loop3.loop_body:                                  ; preds = %[[VAL_82]]
// CHECK-PTX:     %[[VAL_86:.*]] = add nuw nsw i32 %[[VAL_84]], 1
// CHECK-PTX:     store i32 %[[VAL_86]], ptr %[[VAL_25]], align 4
// CHECK-PTX:     %[[VAL_88:.*]] = add i32 %tile_origin.0, 0
// CHECK-PTX:     %[[VAL_89:.*]] = add i32 %tile_origin.1, %[[VAL_46]]
// CHECK-PTX:     %[[VAL_90:.*]] = add i32 %tile_origin.2, %[[VAL_81]]
// CHECK-PTX:     %[[VAL_91:.*]] = add i32 %tile_origin.3, %[[VAL_84]]
// CHECK-PTX:     %[[VAL_92:.*]] = mul nuw nsw i32 %[[VAL_91]], 1
// CHECK-PTX:     %[[VAL_93:.*]] = add nuw nsw i32 0, %[[VAL_92]]
// CHECK-PTX:     %[[VAL_94:.*]] = mul nuw nsw i32 %[[VAL_90]], 2
// CHECK-PTX:     %[[VAL_95:.*]] = add nuw nsw i32 %[[VAL_93]], %[[VAL_94]]
// CHECK-PTX:     %[[VAL_96:.*]] = udiv i32 %[[VAL_95]], 1024
// CHECK-PTX:     %[[VAL_97:.*]] = mul nuw nsw i32 %[[VAL_89]], 1
// CHECK-PTX:     %[[VAL_98:.*]] = add nuw nsw i32 0, %[[VAL_97]]
// CHECK-PTX:     %[[VAL_99:.*]] = udiv i32 %[[VAL_98]], 131072
// CHECK-PTX:     %[[VAL_100:.*]] = mul nuw nsw i32 %[[VAL_88]], 1
// CHECK-PTX:     %[[VAL_101:.*]] = add nuw nsw i32 0, %[[VAL_100]]
// CHECK-PTX:     %[[VAL_102:.*]] = getelementptr inbounds [131072 x [1024 x float]], ptr %[[VAL_103:.*]], i32 0, i32 %[[VAL_98]], i32 %[[VAL_95]]
// CHECK-PTX:     %[[VAL_104:.*]] = load float, ptr %[[VAL_102]], align 4, !invariant.load !7
// CHECK-PTX:     store float %[[VAL_104]], ptr %[[VAL_29]], align 4
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_28]], ptr %[[VAL_29]], ptr %[[VAL_24]])
// CHECK-PTX:     %[[VAL_105:.*]] = load float, ptr %[[VAL_24]], align 4
// CHECK-PTX:     store float %[[VAL_105]], ptr %[[VAL_28]], align 4
// CHECK-PTX:     br label %[[VAL_82]], !llvm.loop !8

// CHECK-PTX:   loop3.loop_exit:                                  ; preds = %[[VAL_82]]
// CHECK-PTX:     br label %[[VAL_74]], !llvm.loop !9

// CHECK:       loop2.loop_exit:                                  ; preds = %[[VAL_74]]
// CHECK:         br label %[[VAL_45]]
// CHECK:       is_full_tile-false:                               ; preds = %[[VAL_49]]
// CHECK:         store i32 0, ptr{{.*}} %[[VAL_23]], align 4
// CHECK:         br label %[[VAL_106:.*]]

// CHECK:       loop2.loop_header{{(5|4)}}:                               ; preds = %[[VAL_107:.*]], %[[VAL_53]]
// CHECK:         %[[VAL_108:.*]] = load i32, ptr{{.*}} %[[VAL_23]], align 4
// CHECK-PTX:     %[[VAL_109:.*]] = icmp uge i32 %[[VAL_108]], 512
// CHECK-GCN:     %[[VAL_109:.*]] = icmp uge i32 %[[VAL_108]], 1024
// CHECK:         br i1 %[[VAL_109]], label %[[VAL_54]], label %[[VAL_110:.*]]

// CHECK:       loop2.loop_body{{(6|5)}}:                                 ; preds = %[[VAL_106]]
// CHECK:         %[[VAL_111:.*]] = add nuw nsw i32 %[[VAL_108]], 64
// CHECK:         store i32 %[[VAL_111]], ptr{{.*}} %[[VAL_23]], align 4
// CHECK:         %[[VAL_113:.*]] = add i32 %[[VAL_108]], %thread.id.2
// CHECK-PTX:     %[[VAL_114:.*]] = icmp ult i32 %[[VAL_113]], 512
// CHECK-GCN:     %[[VAL_114:.*]] = icmp ult i32 %[[VAL_113]], 1024
// CHECK:         br i1 %[[VAL_114]], label %[[VAL_115:.*]], label %[[VAL_107]]

// CHECK:       x_in_tile-after:                                  ; preds = %[[VAL_116:.*]], %[[VAL_110]]
// CHECK:         br label %[[VAL_106]], !llvm.loop !{{(11|9)}}

// CHECK:       loop2.loop_exit{{(4|3)}}:                                 ; preds = %[[VAL_106]]
// CHECK:         br label %[[VAL_45]]

// CHECK:       x_in_tile-true:                                   ; preds = %[[VAL_110]]
// CHECK-GCN:     %[[VAL_123:.*]] = add i32 %tile_origin.0, 0
// CHECK-GCN:     %[[VAL_124:.*]] = add i32 %tile_origin.1, %[[VAL_46]]
// CHECK-GCN:     %[[VAL_125:.*]] = add i32 %tile_origin.2, %[[VAL_113]]
// CHECK-GCN:     %[[VAL_137:.*]] = getelementptr inbounds [131072 x [1024 x float]], ptr %[[VAL_103]], i32 0, i32 %[[VAL_124]], i32 %[[VAL_125]]
// CHECK-GCN:     %[[VAL_138:.*]] = load float, ptr %[[VAL_137]], align 4, !invariant.load !6
// CHECK-GCN:     store float %[[VAL_138]], ptr{{.*}} %[[VAL_29]], align 4
// CHECK-GCN:     %[[VAL_139_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_28]] to ptr
// CHECK-GCN:     %[[VAL_139_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_29]] to ptr
// CHECK-GCN:     %[[VAL_139_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_21]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_139_1]], ptr %[[VAL_139_2]], ptr %[[VAL_139_3]])
// CHECK-GCN:     %[[VAL_139:.*]] = load float, ptr{{.*}} %[[VAL_21]], align 4
// CHECK-GCN:     store float %[[VAL_139]], ptr{{.*}} %[[VAL_28]], align 4
// CHECK-PTX:     store i32 0, ptr %[[VAL_22]], align 4
// CHECK:         br label %[[VAL_117:.*]]

// CHECK-PTX:   loop3.loop_header11:                              ; preds = %[[VAL_118:.*]], %[[VAL_115]]
// CHECK-PTX:     %[[VAL_119:.*]] = load i32, ptr %[[VAL_22]], align 4
// CHECK-PTX:     %[[VAL_120:.*]] = icmp uge i32 %[[VAL_119]], 2
// CHECK-PTX:     br i1 %[[VAL_120]], label %[[VAL_116]], label %[[VAL_118]]

// CHECK-PTX:   loop3.loop_body12:                                ; preds = %[[VAL_117]]
// CHECK-PTX:     %[[VAL_121:.*]] = add nuw nsw i32 %[[VAL_119]], 1
// CHECK-PTX:     store i32 %[[VAL_121]], ptr %[[VAL_22]], align 4
// CHECK-PTX:     %[[VAL_123:.*]] = add i32 %tile_origin.0, 0
// CHECK-PTX:     %[[VAL_124:.*]] = add i32 %tile_origin.1, %[[VAL_46]]
// CHECK-PTX:     %[[VAL_125:.*]] = add i32 %tile_origin.2, %[[VAL_113]]
// CHECK-PTX:     %[[VAL_126:.*]] = add i32 %tile_origin.3, %[[VAL_119]]
// CHECK-PTX:     %[[VAL_127:.*]] = mul nuw nsw i32 %[[VAL_126]], 1
// CHECK-PTX:     %[[VAL_128:.*]] = add nuw nsw i32 0, %[[VAL_127]]
// CHECK-PTX:     %[[VAL_129:.*]] = mul nuw nsw i32 %[[VAL_125]], 2
// CHECK-PTX:     %[[VAL_130:.*]] = add nuw nsw i32 %[[VAL_128]], %[[VAL_129]]
// CHECK-PTX:     %[[VAL_131:.*]] = udiv i32 %[[VAL_130]], 1024
// CHECK-PTX:     %[[VAL_132:.*]] = mul nuw nsw i32 %[[VAL_124]], 1
// CHECK-PTX:     %[[VAL_133:.*]] = add nuw nsw i32 0, %[[VAL_132]]
// CHECK-PTX:     %[[VAL_134:.*]] = udiv i32 %[[VAL_133]], 131072
// CHECK-PTX:     %[[VAL_135:.*]] = mul nuw nsw i32 %[[VAL_123]], 1
// CHECK-PTX:     %[[VAL_136:.*]] = add nuw nsw i32 0, %[[VAL_135]]
// CHECK-PTX:     %[[VAL_137:.*]] = getelementptr inbounds [131072 x [1024 x float]], ptr %[[VAL_103]], i32 0, i32 %[[VAL_133]], i32 %[[VAL_130]]
// CHECK-PTX:     %[[VAL_138:.*]] = load float, ptr %[[VAL_137]], align 4, !invariant.load !7
// CHECK-PTX:     store float %[[VAL_138]], ptr %[[VAL_29]], align 4
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_28]], ptr %[[VAL_29]], ptr %[[VAL_21]])
// CHECK-PTX:     %[[VAL_139:.*]] = load float, ptr %[[VAL_21]], align 4
// CHECK-PTX:     store float %[[VAL_139]], ptr %[[VAL_28]], align 4
// CHECK-PTX:     br label %[[VAL_117]], !llvm.loop !12

// CHECK-PTX:   loop3.loop_exit10:                                ; preds = %[[VAL_117]]
// CHECK-PTX:     br label %[[VAL_107]]

// CHECK:       thread_in_bounds-true:                            ; preds = %[[VAL_48]]
// CHECK:         %[[VAL_140:.*]] = icmp eq i32 %lane_id, 0
// CHECK:         br i1 %[[VAL_140]], label %[[VAL_141:.*]], label %[[VAL_142:.*]]

// CHECK:       intra_warp_reduce_write-after:                    ; preds = %[[VAL_141]], %thread_in_bounds-true
// CHECK-PTX:     call void @llvm.nvvm.barrier0()
// CHECK-GCN:     fence syncscope("workgroup") seq_cst
// CHECK-GCN:     call void @llvm.amdgcn.s.barrier()
// CHECK:         %[[VAL_143:.*]] = icmp eq i32 %[[VAL_71]], 0
// CHECK:         br i1 %[[VAL_143]], label %[[VAL_144:.*]], label %[[VAL_73]]

// CHECK:       inter_warp_reduce-after:                          ; preds = %[[VAL_145:.*]], %[[VAL_142]]
// CHECK:         br label %thread_in_bounds-after

// CHECK:       intra_warp_reduce_write-true:                     ; preds = %thread_in_bounds-true
// CHECK:         %[[VAL_146:.*]] = load float, ptr{{.*}} %[[VAL_28]], align 4
// CHECK:         %[[VAL_147:.*]] = getelementptr inbounds [4 x [2 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.1, i32 %[[VAL_71]]
// CHECK:         %[[VAL_148:.*]] = addrspacecast ptr addrspace(3) %[[VAL_147]] to ptr
// CHECK:         store float %[[VAL_146]], ptr %[[VAL_148]], align 4
// CHECK:         br label %[[VAL_142]]

// CHECK:       inter_warp_reduce-true:                           ; preds = %[[VAL_142]]
// CHECK:         %[[VAL_149:.*]] = getelementptr inbounds [4 x [2 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.1, i32 %lane_id
// CHECK:         %[[VAL_150:.*]] = addrspacecast ptr addrspace(3) %[[VAL_149]] to ptr
// CHECK-GCN:     %[[VAL_150_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_10]] to ptr
// CHECK-GCN:     store float %[[VAL_35]], ptr %[[VAL_150_1]], align 4
// CHECK-PTX:     store float %[[VAL_35]], ptr %[[VAL_10]], align 4
// CHECK:         %[[VAL_151:.*]] = icmp ult i32 %thread.id.2, 2
// CHECK-GCN:     %[[VAL_152:.*]] = select i1 %[[VAL_151]], ptr %[[VAL_150]], ptr %[[VAL_150_1]]
// CHECK-PTX:     %[[VAL_152:.*]] = select i1 %[[VAL_151]], ptr %[[VAL_150]], ptr %[[VAL_10]]
// CHECK:         %[[VAL_153:.*]] = load float, ptr %[[VAL_152]], align 4
// CHECK-GCN:     %[[VAL_154_1:.*]] = bitcast float %[[VAL_153]] to i32
// CHECK-GCN:     %[[VAL_154_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_154_1]], i32 543)
// CHECK-GCN:     %[[VAL_154:.*]] = bitcast i32 %[[VAL_154_2]] to float
// CHECK-PTX:     %[[VAL_154:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_153]], i32 16, i32 31)
// CHECK:         store float %[[VAL_154]], ptr{{.*}} %[[VAL_9]], align 4
// CHECK-GCN:     %[[VAL_155_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_9]] to ptr
// CHECK-GCN:     %[[VAL_155_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_8]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_155_1]], ptr %[[VAL_155_2]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_9]], ptr %[[VAL_8]])
// CHECK:         %[[VAL_155:.*]] = load float, ptr{{.*}} %[[VAL_8]], align 4
// CHECK:         store float %[[VAL_155]], ptr %[[VAL_152]], align 4
// CHECK:         %[[VAL_156:.*]] = load float, ptr %[[VAL_152]], align 4
// CHECK-GCN:     %[[VAL_157_1:.*]] = bitcast float %[[VAL_156]] to i32
// CHECK-GCN:     %[[VAL_157_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_157_1]], i32 287)
// CHECK-GCN:     %[[VAL_157:.*]] = bitcast i32 %[[VAL_157_2]] to float
// CHECK-PTX:     %[[VAL_157:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_156]], i32 8, i32 31)
// CHECK:         store float %[[VAL_157]], ptr{{.*}} %[[VAL_7]], align 4
// CHECK-GCN:     %[[VAL_158_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_7]] to ptr
// CHECK-GCN:     %[[VAL_158_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_6]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_158_1]], ptr %[[VAL_158_2]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_7]], ptr %[[VAL_6]])
// CHECK:         %[[VAL_158:.*]] = load float, ptr{{.*}} %[[VAL_6]], align 4
// CHECK:         store float %[[VAL_158]], ptr %[[VAL_152]], align 4
// CHECK:         %[[VAL_159:.*]] = load float, ptr %[[VAL_152]], align 4
// CHECK-GCN:     %[[VAL_160_1:.*]] = bitcast float %[[VAL_159]] to i32
// CHECK-GCN:     %[[VAL_160_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_160_1]], i32 159)
// CHECK-GCN:     %[[VAL_160:.*]] = bitcast i32 %[[VAL_160_2]] to float
// CHECK-PTX:     %[[VAL_160:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_159]], i32 4, i32 31)
// CHECK:         store float %[[VAL_160]], ptr{{.*}} %[[VAL_5]], align 4
// CHECK-GCN:     %[[VAL_161_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_5]] to ptr
// CHECK-GCN:     %[[VAL_161_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_4]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_161_1]], ptr %[[VAL_161_2]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_5]], ptr %[[VAL_4]])
// CHECK:         %[[VAL_161:.*]] = load float, ptr{{.*}} %[[VAL_4]], align 4
// CHECK:         store float %[[VAL_161]], ptr %[[VAL_152]], align 4
// CHECK:         %[[VAL_162:.*]] = load float, ptr %[[VAL_152]], align 4
// CHECK-GCN:     %[[VAL_163_1:.*]] = bitcast float %[[VAL_162]] to i32
// CHECK-GCN:     %[[VAL_163_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_163_1]], i32 95)
// CHECK-GCN:     %[[VAL_163:.*]] = bitcast i32 %[[VAL_163_2]] to float
// CHECK-PTX:     %[[VAL_163:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_162]], i32 2, i32 31)
// CHECK:         store float %[[VAL_163]], ptr{{.*}} %[[VAL_3]], align 4
// CHECK-GCN:     %[[VAL_164_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_3]] to ptr
// CHECK-GCN:     %[[VAL_164_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_2]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_164_1]], ptr %[[VAL_164_2]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_3]], ptr %[[VAL_2]])
// CHECK:         %[[VAL_164:.*]] = load float, ptr{{.*}} %[[VAL_2]], align 4
// CHECK:         store float %[[VAL_164]], ptr %[[VAL_152]], align 4
// CHECK:         %[[VAL_165:.*]] = load float, ptr %[[VAL_152]], align 4
// CHECK-GCN:     %[[VAL_166_1:.*]] = bitcast float %[[VAL_165]] to i32
// CHECK-GCN:     %[[VAL_166_2:.*]] = call i32 @llvm.amdgcn.ds.swizzle(i32 %[[VAL_166_1]], i32 63)
// CHECK-GCN:     %[[VAL_166:.*]] = bitcast i32 %[[VAL_166_2]] to float
// CHECK-PTX:     %[[VAL_166:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_165]], i32 1, i32 31)
// CHECK:         store float %[[VAL_166]], ptr{{.*}} %[[VAL_1]], align 4
// CHECK-GCN:     %[[VAL_167_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_1]] to ptr
// CHECK-GCN:     %[[VAL_167_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_0]] to ptr
// CHECK-GCN:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_167_1]], ptr %[[VAL_167_2]])
// CHECK-PTX:     call void @[[SUM]](ptr %[[VAL_152]], ptr %[[VAL_1]], ptr %[[VAL_0]])
// CHECK:         %[[VAL_167:.*]] = load float, ptr{{.*}} %[[VAL_0]], align 4
// CHECK:         store float %[[VAL_167]], ptr %[[VAL_152]], align 4
// CHECK:         %[[VAL_168:.*]] = icmp eq i32 %thread.id.2, 0
// CHECK:         br i1 %[[VAL_168]], label %[[VAL_169:.*]], label %[[VAL_145]]

// CHECK:       reduction_write_output-after:                     ; preds = %[[VAL_169]], %[[VAL_144]]
// CHECK:         br label %[[VAL_73]]
// CHECK:       reduction_write_output-true:                      ; preds = %[[VAL_144]]
// CHECK:         %[[VAL_171:.*]] = add i32 %tile_origin.1, %thread.id.1
// CHECK:         %[[VAL_175:.*]] = getelementptr inbounds [131072 x float], ptr %[[VAL_176:.*]], i32 0, i32 %[[VAL_171]]
// CHECK:         %[[VAL_177:.*]] = load float, ptr %[[VAL_152]], align 4
// CHECK:         store float %[[VAL_177]], ptr %[[VAL_175]], align 4
// CHECK:         br label %[[VAL_145]]
// CHECK:       entry:
// CHECK:         %[[VAL_178:.*]] = alloca float, align 4
// CHECK:         %[[VAL_179:.*]] = load float, ptr %[[VAL_180:.*]], align 4
// CHECK:         %[[VAL_181:.*]] = load float, ptr %[[VAL_182:.*]], align 4
// CHECK:         %[[VAL_183:.*]] = fadd float %[[VAL_179]], %[[VAL_181]]
// CHECK:         store float %[[VAL_183]], ptr{{.*}} %[[VAL_178]], align 4
// CHECK:         %[[VAL_184:.*]] = load float, ptr{{.*}} %[[VAL_178]], align 4
// CHECK:         store float %[[VAL_184]], ptr %[[VAL_185:.*]], align 4
// CHECK:         ret void
