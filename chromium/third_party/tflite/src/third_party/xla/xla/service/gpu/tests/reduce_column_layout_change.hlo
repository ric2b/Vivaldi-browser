// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/%{GPU}.txtpb | FileCheck %s --check-prefixes=CHECK,CHECK-%{PTX}

HloModule reduce_with_layout_change, is_scheduled=true

reduction0 {
  x0 = f32[] parameter(0)
  y0 = f32[] parameter(1)
  ROOT add0 = f32[] add(x0, y0)
}

fused_computation {
  arg0 = f32[12,3,32,16,32,4,3,12] parameter(0)
  constant0 = f32[] constant(0)
  ROOT reduce0 = f32[16,32,4,3,12]{1,3,2,0,4} reduce(arg0, constant0), dimensions={0,1,2}, to_apply=reduction0
}

ENTRY kernel_entry {
  arg0 = f32[12,3,32,16,32,4,3,12] parameter(0)
  ROOT fusion = f32[16,32,4,3,12]{1,3,2,0,4} fusion(arg0), kind=kInput, calls=fused_computation
}

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = alloca float, align 4
// CHECK:         %[[VAL_1:.*]] = alloca float, align 4
// CHECK:         %[[VAL_2:.*]] = alloca float, align 4
// CHECK:         %[[VAL_3:.*]] = alloca float, align 4
// CHECK:         %[[VAL_4:.*]] = alloca float, align 4
// CHECK:         %[[VAL_5:.*]] = alloca float, align 4
// CHECK:         %[[VAL_6:.*]] = alloca float, align 4
// CHECK:         %[[VAL_7:.*]] = alloca float, align 4
// CHECK:         %[[VAL_8:.*]] = alloca float, align 4
// CHECK:         %[[VAL_9:.*]] = alloca float, align 4
// CHECK:         %[[VAL_10:.*]] = alloca float, align 4
// CHECK:         %[[VAL_11:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_12:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_13:.*]] = alloca float, align 4
// CHECK:         %[[VAL_14:.*]] = alloca float, align 4
// CHECK-PTX:     %[[VAL_15:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !2
// CHECK-GCN:     %[[VAL_15:.*]] = call i32 @llvm.amdgcn.workgroup.id.y
// CHECK:         %[[VAL_16:.*]] = icmp eq i32 %[[VAL_15]], 0
// CHECK:         br i1 %[[VAL_16]], label %[[VAL_17:.*]], label %[[VAL_18:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_19:.*]], %[[VAL_20:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_20]]
// CHECK:         %[[VAL_21:.*]] = load float, ptr @0, align 4
// CHECK:         store float %[[VAL_21]], ptr{{( addrspace\(5\))?}} %[[VAL_13]], align 4
// CHECK-PTX:     %thread.id.x = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !3
// CHECK-GCN:     %thread.id.x = call i32 @llvm.amdgcn.workitem.id.x
// CHECK-PTX:     %block.id.x = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
// CHECK-GCN:     %block.id.x = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %[[VAL_22:.*]] = udiv i32 %thread.id.x, 32
// CHECK:         %thread.id.1 = urem i32 %[[VAL_22]], 32
// CHECK:         %thread.id.2 = urem i32 %thread.id.x, 32
// CHECK:         %lane_id = urem i32 %thread.id.x, 32
// CHECK:         %[[VAL_23:.*]] = udiv i32 %block.id.x, 1
// CHECK:         %[[VAL_24:.*]] = urem i32 %[[VAL_23]], 2304
// CHECK:         %[[VAL_25:.*]] = udiv i32 %block.id.x, 2304
// CHECK:         %[[VAL_26:.*]] = urem i32 %[[VAL_25]], 1
// CHECK:         %[[VAL_27:.*]] = udiv i32 %block.id.x, 2304
// CHECK:         %[[VAL_28:.*]] = icmp eq i32 %[[VAL_26]], 0
// CHECK:         %tile_bound.1 = select i1 %[[VAL_28]], i32 1152, i32 4096
// CHECK:         %tile_origin.0 = mul i32 %[[VAL_27]], 1
// CHECK:         %tile_origin.1 = mul i32 %[[VAL_26]], 4096
// CHECK:         %tile_origin.2 = mul i32 %[[VAL_24]], 32
// CHECK:         store i32 %thread.id.1, ptr{{( addrspace\(5\))?}} %[[VAL_12]], align 4
// CHECK:         br label %[[VAL_29:.*]]
// CHECK:       loop1.loop_header:                                ; preds = %[[VAL_30:.*]], %[[VAL_17]]
// CHECK:         %[[VAL_31:.*]] = load i32, ptr{{( addrspace\(5\))?}} %[[VAL_12]], align 4
// CHECK:         %[[VAL_32:.*]] = icmp uge i32 %[[VAL_31]], %tile_bound.1
// CHECK:         br i1 %[[VAL_32]], label %[[VAL_33:.*]], label %[[VAL_34:.*]]
// CHECK:       loop1.loop_body:                                  ; preds = %[[VAL_29]]
// CHECK:         %[[VAL_35:.*]] = add nuw nsw i32 %[[VAL_31]], 32
// CHECK:         store i32 %[[VAL_35]], ptr{{( addrspace\(5\))?}} %[[VAL_12]], align 4
// CHECK:         store i32 0, ptr{{( addrspace\(5\))?}} %[[VAL_11]], align 4
// CHECK:         br label %[[VAL_37:.*]]
// CHECK:       loop2.loop_header:                                ; preds = %[[VAL_38:.*]], %[[VAL_34]]
// CHECK:         %[[VAL_39:.*]] = load i32, ptr{{( addrspace\(5\))?}} %[[VAL_11]], align 4
// CHECK:         %[[VAL_40:.*]] = icmp uge i32 %[[VAL_39]], 32
// CHECK:         br i1 %[[VAL_40]], label %[[VAL_30]], label %[[VAL_41:.*]]
// CHECK:       loop2.loop_body:                                  ; preds = %[[VAL_37]]
// CHECK:         %[[VAL_42:.*]] = add nuw nsw i32 %[[VAL_39]], 32
// CHECK:         store i32 %[[VAL_42]], ptr{{( addrspace\(5\))?}} %[[VAL_11]], align 4
// CHECK:         %[[VAL_44:.*]] = add i32 %[[VAL_39]], %thread.id.2
// CHECK:         %[[VAL_45:.*]] = icmp ult i32 %[[VAL_44]], 32
// CHECK:         br i1 %[[VAL_45]], label %[[VAL_46:.*]], label %[[VAL_38]]
// CHECK:       x_in_tile-after:                                  ; preds = %[[VAL_46]], %[[VAL_41]]
// CHECK:         br label %[[VAL_37]], !llvm.loop
// CHECK:       loop2.loop_exit:                                  ; preds = %[[VAL_37]]
// CHECK:         br label %[[VAL_29]], !llvm.loop
// CHECK:       loop1.loop_exit:                                  ; preds = %[[VAL_29]]
// CHECK:         %[[VAL_47:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_13]], align 4
// CHECK:         %[[VAL_48:.*]] = getelementptr inbounds [32 x [33 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.2, i32 %thread.id.1
// CHECK:         %[[VAL_49:.*]] = addrspacecast ptr addrspace(3) %[[VAL_48]] to ptr
// CHECK:         store float %[[VAL_47]], ptr %[[VAL_49]], align 4
// CHECK-PTX:         call void @llvm.nvvm.barrier0()
// CHECK-GCN:         call void @llvm.amdgcn.s.barrier()
// CHECK:         %[[VAL_50:.*]] = getelementptr inbounds [32 x [33 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.1, i32 %thread.id.2
// CHECK:         %[[VAL_51:.*]] = addrspacecast ptr addrspace(3) %[[VAL_50]] to ptr
// CHECK:         %[[VAL_52:.*]] = load float, ptr %[[VAL_51]], align 4
// CHECK-PTX:         %[[VAL_53:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_52]], i32 16, i32 31)
// CHECK-GCN:         %[[VAL_53_:.*]] = call i32 @llvm.amdgcn.ds.swizzle
// CHECK-GCN:         %[[VAL_53:.*]] = bitcast i32
// CHECK:         store float %[[VAL_53]], ptr{{( addrspace\(5\))?}} %[[VAL_9]], align 4
// CHECK-PTX:         call void @[[REDUCTION0:reduction0.*]](ptr %[[VAL_51]], ptr %[[VAL_9]], ptr %[[VAL_8]])
// CHECK:         %[[VAL_54:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_8]], align 4
// CHECK:         store float %[[VAL_54]], ptr %[[VAL_51]], align 4
// CHECK:         %[[VAL_55:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK-PTX:         %[[VAL_56:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_55]], i32 8, i32 31)
// CHECK-GCN:         %[[VAL_56_1_:.*]] = call i32 @llvm.amdgcn.ds.swizzle
// CHECK-GCN:         %[[VAL_56:.*]] = bitcast i32
// CHECK:         store float %[[VAL_56]], ptr{{( addrspace\(5\))?}} %[[VAL_7]], align 4
// CHECK-PTX:         call void @[[REDUCTION0]](ptr %[[VAL_51]], ptr %[[VAL_7]], ptr %[[VAL_6]])
// CHECK:         %[[VAL_57:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_6]], align 4
// CHECK:         store float %[[VAL_57]], ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK:         %[[VAL_58:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK-PTX:         %[[VAL_59:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_58]], i32 4, i32 31)
// CHECK-GCN:         %[[VAL_59_:.*]] = call i32 @llvm.amdgcn.ds.swizzle
// CHECK-GCN:         %[[VAL_59:.*]] = bitcast i32
// CHECK:         store float %[[VAL_59]], ptr{{( addrspace\(5\))?}} %[[VAL_5]], align 4
// CHECK-PTX:         call void @[[REDUCTION0]](ptr %[[VAL_51]], ptr %[[VAL_5]], ptr %[[VAL_4]])
// CHECK:         %[[VAL_60:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_4]], align 4
// CHECK:         store float %[[VAL_60]], ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK:         %[[VAL_61:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK-PTX:         %[[VAL_62:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_61]], i32 2, i32 31)
// CHECK-GCN:         %[[VAL_62_:.*]] = call i32 @llvm.amdgcn.ds.swizzle
// CHECK-GCN:         %[[VAL_62:.*]] = bitcast i32
// CHECK:         store float %[[VAL_62]], ptr{{( addrspace\(5\))?}} %[[VAL_3]], align 4
// CHECK-PTX:         call void @[[REDUCTION0]](ptr %[[VAL_51]], ptr %[[VAL_3]], ptr %[[VAL_2]])
// CHECK:         %[[VAL_63:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_2]], align 4
// CHECK:         store float %[[VAL_63]], ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK:         %[[VAL_64:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK-PTX:         %[[VAL_65:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_64]], i32 1, i32 31)
// CHECK-GCN:         %[[VAL_65_:.*]] = call i32 @llvm.amdgcn.ds.swizzle
// CHECK-GCN:         %[[VAL_65:.*]] = bitcast i32
// CHECK:         store float %[[VAL_65]], ptr{{( addrspace\(5\))?}} %[[VAL_1]], align 4
// CHECK-PTX:         call void @[[REDUCTION0]](ptr %[[VAL_51]], ptr %[[VAL_1]], ptr %[[VAL_0]])
// CHECK:         %[[VAL_66:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_0]], align 4
// CHECK:         store float %[[VAL_66]], ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK-PTX:         %[[VAL_67:.*]] = icmp ult i32 %thread.id.1, 32
// CHECK-PTX:         %[[VAL_68:.*]] = icmp ult i32 %thread.id.2, %tile_bound.1
// CHECK-GCN:         %[[VAL_68:.*]] = icmp ult i32 %thread.id.2, %tile_bound.1
// CHECK-GCN:         %[[VAL_67:.*]] = icmp ult i32 %thread.id.1, 32
// CHECK:         %[[VAL_69:.*]] = and i1 %[[VAL_67]], %[[VAL_68]]
// CHECK:         %[[VAL_70:.*]] = icmp eq i32 %lane_id, 0
// CHECK:         %[[VAL_71:.*]] = and i1 %[[VAL_69]], %[[VAL_70]]
// CHECK:         br i1 %[[VAL_71]], label %[[VAL_72:.*]], label %[[VAL_19]]
// CHECK:       reduction_write_output-after:                     ; preds = %[[VAL_72]], %[[VAL_33]]
// CHECK:         br label %[[VAL_18]]
// CHECK:       x_in_tile-true:                                   ; preds = %[[VAL_41]]
// CHECK:         %[[VAL_73:.*]] = add i32 %tile_origin.0, 0
// CHECK:         %[[VAL_74:.*]] = add i32 %tile_origin.1, %[[VAL_31]]
// CHECK:         %[[VAL_75:.*]] = add i32 %tile_origin.2, %[[VAL_44]]
// CHECK:         %[[VAL_76:.*]] = mul nuw nsw i32 %[[VAL_75]], 1
// CHECK:         %[[VAL_77:.*]] = add nuw nsw i32 0, %[[VAL_76]]
// CHECK:         %[[VAL_78:.*]] = urem i32 %[[VAL_77]], 12
// CHECK:         %[[VAL_79:.*]] = udiv i32 %[[VAL_77]], 12
// CHECK:         %[[VAL_80:.*]] = urem i32 %[[VAL_79]], 3
// CHECK:         %[[VAL_81:.*]] = udiv i32 %[[VAL_79]], 3
// CHECK:         %[[VAL_82:.*]] = urem i32 %[[VAL_81]], 4
// CHECK:         %[[VAL_83:.*]] = udiv i32 %[[VAL_81]], 4
// CHECK:         %[[VAL_84:.*]] = urem i32 %[[VAL_83]], 32
// CHECK:         %[[VAL_85:.*]] = udiv i32 %[[VAL_83]], 32
// CHECK:         %[[VAL_86:.*]] = udiv i32 %[[VAL_85]], 16
// CHECK:         %[[VAL_87:.*]] = mul nuw nsw i32 %[[VAL_74]], 1
// CHECK:         %[[VAL_88:.*]] = add nuw nsw i32 0, %[[VAL_87]]
// CHECK:         %[[VAL_89:.*]] = urem i32 %[[VAL_88]], 32
// CHECK:         %[[VAL_90:.*]] = udiv i32 %[[VAL_88]], 32
// CHECK:         %[[VAL_91:.*]] = urem i32 %[[VAL_90]], 3
// CHECK:         %[[VAL_92:.*]] = udiv i32 %[[VAL_90]], 3
// CHECK:         %[[VAL_93:.*]] = udiv i32 %[[VAL_92]], 12
// CHECK:         %[[VAL_94:.*]] = mul nuw nsw i32 %[[VAL_73]], 1
// CHECK:         %[[VAL_95:.*]] = add nuw nsw i32 0, %[[VAL_94]]
// CHECK:         %[[VAL_96:.*]] = getelementptr inbounds [12 x [3 x [32 x [16 x [32 x [4 x [3 x [12 x float]]]]]]]], ptr %[[VAL_97:.*]], i32 0, i32 %[[VAL_92]], i32 %[[VAL_91]], i32 %[[VAL_89]], i32 %[[VAL_85]], i32 %[[VAL_84]], i32 %[[VAL_82]], i32 %[[VAL_80]], i32 %[[VAL_78]]
// CHECK:         %[[VAL_98:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_96]], align 4, !invariant.load
// CHECK:         store float %[[VAL_98]], ptr{{( addrspace\(5\))?}} %[[VAL_14]], align 4
// CHECK-PTX:         call void @[[REDUCTION0]](ptr %[[VAL_13]], ptr %[[VAL_14]], ptr %[[VAL_10]])
// CHECK:         %[[VAL_99:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_10]], align 4
// CHECK:         store float %[[VAL_99]], ptr{{( addrspace\(5\))?}} %[[VAL_13]], align 4
// CHECK:         br label %[[VAL_38]]
// CHECK:       reduction_write_output-true:                      ; preds = %[[VAL_33]]
// CHECK:         %[[VAL_100:.*]] = add i32 %tile_origin.2, %thread.id.1
// CHECK:         %[[VAL_101:.*]] = mul nuw nsw i32 %[[VAL_100]], 1
// CHECK:         %[[VAL_102:.*]] = add nuw nsw i32 0, %[[VAL_101]]
// CHECK:         %[[VAL_103:.*]] = urem i32 %[[VAL_102]], 12
// CHECK:         %[[VAL_104:.*]] = udiv i32 %[[VAL_102]], 12
// CHECK:         %[[VAL_105:.*]] = urem i32 %[[VAL_104]], 3
// CHECK:         %[[VAL_106:.*]] = udiv i32 %[[VAL_104]], 3
// CHECK:         %[[VAL_107:.*]] = urem i32 %[[VAL_106]], 4
// CHECK:         %[[VAL_108:.*]] = udiv i32 %[[VAL_106]], 4
// CHECK:         %[[VAL_109:.*]] = urem i32 %[[VAL_108]], 32
// CHECK:         %[[VAL_110:.*]] = udiv i32 %[[VAL_108]], 32
// CHECK:         %[[VAL_111:.*]] = udiv i32 %[[VAL_110]], 16
// CHECK:         %[[VAL_112:.*]] = mul nuw nsw i32 %tile_origin.0, 1
// CHECK:         %[[VAL_113:.*]] = add nuw nsw i32 0, %[[VAL_112]]
// CHECK:         %[[VAL_114:.*]] = getelementptr inbounds [12 x [16 x [4 x [3 x [32 x float]]]]], ptr %[[VAL_115:.*]], i32 0, i32 %[[VAL_103]], i32 %[[VAL_110]], i32 %[[VAL_107]], i32 %[[VAL_105]], i32 %[[VAL_109]]
// CHECK:         %[[VAL_116:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_51]], align 4
// CHECK:         store float %[[VAL_116]], ptr{{( addrspace\(5\))?}} %[[VAL_114]], align 4
// CHECK:         br label %[[VAL_19]]
// CHECK:       entry:
// CHECK:         %[[VAL_117:.*]] = alloca float, align 4
// CHECK:         %[[VAL_118:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_119:.*]], align 4
// CHECK:         %[[VAL_120:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_121:.*]], align 4
// CHECK:         %[[VAL_122:.*]] = fadd float %[[VAL_118]], %[[VAL_120]]
// CHECK:         store float %[[VAL_122]], ptr{{( addrspace\(5\))?}} %[[VAL_117]], align 4
// CHECK:         %[[VAL_123:.*]] = load float, ptr{{( addrspace\(5\))?}} %[[VAL_117]], align 4
// CHECK:         store float %[[VAL_123]], ptr{{( addrspace\(5\))?}} %[[VAL_124:.*]], align 4
// CHECK:         ret void
